{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y=np.array([[0,1,1,0]]).T\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    return (1/1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSig(z):\n",
    "    return sig(z)*(1-sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hidden layer weights\n",
    "wh= 2*np.random.random((2,2))-1\n",
    "bh= 2*np.random.random((1,2))-1\n",
    "wo= 2*np.random.random((2,1))-1\n",
    "bo=2*np.random.random((1,1))-1\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # forward propagation without any hidden layer\n",
    "# for iter in range(10000):\n",
    "#     output0 = X # same as input \n",
    "#     output = sig(np.dot(output0, weights) + bias)\n",
    "\n",
    "#     first_term = output - Y # yp-ya \n",
    "#     input_for_last_layer = np.dot(output0, weights) + bias # this is the entire input coming to jth unit ( inputj )\n",
    "#     second_term = derivativeSig(input_for_last_layer) # oj(i-oj)\n",
    "#     first_two = first_term * second_term\n",
    "#     first_two.shape # ( 4*1)\n",
    "\n",
    "#     changes = np.array([[0.0],[0.0]]) # same as shape of weights as we want changes in weights )\n",
    "\n",
    "#     for i in range(2): # iterating over features \n",
    "#         for j in range(4): # iterating over each row \n",
    "#             changes[i][0] += first_two[j][0] * output0[j][i]\n",
    "#     weights = weights - lr*changes\n",
    "#     bias_change = 0.0\n",
    "#     for j in range(4):\n",
    "#         bias_change += first_two[j][0] * 1\n",
    "#     bias = bias - lr * bias_change\n",
    "# output = sig(np.dot(X, weights) + bias)\n",
    "# weights, bias, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.00000052],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]]), array([[-0.87866729,  0.40317905],\n",
       "        [-0.8692688 ,  0.4759141 ]]), array([[-1.57431166,  0.62609583]]), array([[1.97323448],\n",
       "        [1.11180483]]), array([[1.2583033]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward+backward with one hidden layer\n",
    "for iter in range(10000):\n",
    "    output0=X\n",
    "    inputHidden=np.dot(output0,wh)+bh\n",
    "    outputHidden=sig(inputHidden)\n",
    "    inputForOutputLayer=np.dot(outputHidden,wo)+bo\n",
    "    output= sig(inputForOutputLayer)\n",
    "\n",
    "    first_term_output_layer= output-Y\n",
    "    second_term_output_layer=derivativeSig(inputForOutputLayer)\n",
    "    first_two_output_layer= first_term_output_layer * second_term_output_layer\n",
    "\n",
    "    first_term_hidden_layer= np.dot(first_two_output_layer,wo.T)\n",
    "    second_term_hidden_layer=derivativeSig(inputHidden)\n",
    "    first_two_hidden_layer= first_term_hidden_layer * second_term_hidden_layer\n",
    "\n",
    "    changes_output=np.dot(outputHidden.T,first_two_output_layer)\n",
    "    changes_output_bias=np.sum(first_two_output_layer,axis=0,keepdims=True)\n",
    "\n",
    "    changes_hidden=np.dot(output0.T,first_two_hidden_layer)\n",
    "    changes_hidden_bias=np.sum(first_two_hidden_layer,axis=0,keepdims=True)\n",
    "\n",
    "    wo=wo-lr*changes_output\n",
    "    bo=bo-lr*changes_output_bias\n",
    "\n",
    "    wh=wh-lr*changes_hidden\n",
    "    bh=bh -lr*changes_hidden_bias\n",
    "    \n",
    "output0=X\n",
    "inputHidden=np.dot(output0,wh)+bh\n",
    "outputHidden=sig(inputHidden)\n",
    "inputForOutputLayer=np.dot(outputHidden,wo)+bo\n",
    "output= sig(inputForOutputLayer)\n",
    "output,wh,bh,wo,bo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
